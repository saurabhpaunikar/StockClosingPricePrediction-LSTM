{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#to plot within notebook\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#setting figure size\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20,10\n",
    "\n",
    "#for normalizing data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('NSE-TATAGLOBAL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting index as date\n",
    "df['Date'] = pd.to_datetime(df.Date,format='%Y-%m-%d')\n",
    "df.index = df['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataframe with date and the target variable\n",
    "data = df.sort_index(ascending=True, axis=0)\n",
    "new_data = pd.DataFrame(index=range(0,len(df)),columns=['Date', 'Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(data)):\n",
    "     new_data['Date'][i] = data['Date'][i]\n",
    "     new_data['Close'][i] = data['Close'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(df['Close'], label='Close Price history')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE: While splitting the data into train and validation set, we cannot use random splitting since that will destroy the time component. So here we have set the last year’s data into validation and the 4 years’ data before that into train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into train and validation\n",
    "train = new_data[:987]\n",
    "valid = new_data[987:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shapes of training set\n",
    "print('\\n Shape of training set:')\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shapes of validation set\n",
    "print('\\n Shape of validation set:')\n",
    "print(valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In the next step, we will create predictions for the validation set and check the RMSE using the actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making predictions\n",
    "preds = []\n",
    "for i in range(0,valid.shape[0]):\n",
    "    a = train['Close'][len(train)-248+i:].sum() + sum(preds)\n",
    "    b = a/248\n",
    "    preds.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the results (RMSE value)\n",
    "rms=np.sqrt(np.mean(np.power((np.array(valid['Close'])-preds),2)))\n",
    "print('\\n RMSE value on validation set:')\n",
    "print(rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "\n",
    "valid['Predictions'] = 0\n",
    "valid['Predictions'] = preds\n",
    "plt.plot(train['Close'])\n",
    "plt.plot(valid[['Close', 'Predictions']])\n",
    "#plt.xlim([0,1400])\n",
    "#plt.ylim([0,400])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting index as date values\n",
    "df['Date'] = pd.to_datetime(df.Date,format='%Y-%m-%d')\n",
    "df.index = df['Date']\n",
    "\n",
    "#sorting\n",
    "data = df.sort_index(ascending=True, axis=0)\n",
    "\n",
    "#creating a separate dataset\n",
    "new_data = pd.DataFrame(index=range(0,len(df)),columns=['Date', 'Close'])\n",
    "\n",
    "for i in range(0,len(data)):\n",
    "    new_data['Date'][i] = data['Date'][i]\n",
    "    new_data['Close'][i] = data['Close'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from fastai.tabular import add_datepart\n",
    "add_datepart(new_data, 'Date')\n",
    "new_data.drop('Elapsed', axis=1, inplace=True)  #elapsed will be the time stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['mon_fri'] = 0\n",
    "for i in range(0,len(new_data)):\n",
    "    if (new_data['Dayofweek'][i] == 0 or new_data['Dayofweek'][i] == 4):\n",
    "        new_data['mon_fri'][i] = 1\n",
    "    else:\n",
    "        new_data['mon_fri'][i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into train and validation\n",
    "train = new_data[:987]\n",
    "valid = new_data[987:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.drop('Close', axis=1)\n",
    "y_train = train['Close']\n",
    "x_valid = valid.drop('Close', axis=1)\n",
    "y_valid = valid['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions and find the rmse\n",
    "preds = model.predict(x_valid)\n",
    "rms=np.sqrt(np.mean(np.power((np.array(y_valid)-np.array(preds)),2)))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "valid['Predictions'] = 0\n",
    "valid['Predictions'] = preds\n",
    "\n",
    "valid.index = new_data[987:].index\n",
    "train.index = new_data[:987].index\n",
    "\n",
    "plt.plot(train['Close'])\n",
    "plt.plot(valid[['Close', 'Predictions']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling data\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_train = pd.DataFrame(x_train_scaled)\n",
    "x_valid_scaled = scaler.fit_transform(x_valid)\n",
    "x_valid = pd.DataFrame(x_valid_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using gridsearch to find the best parameter\n",
    "params = {'n_neighbors':[2,3,4,5,6,7,8,9]}\n",
    "knn = neighbors.KNeighborsRegressor()\n",
    "model = GridSearchCV(knn, params, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model and make predictions\n",
    "model.fit(x_train,y_train)\n",
    "preds = model.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms=np.sqrt(np.mean(np.power((np.array(y_valid)-np.array(preds)),2)))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "valid['Predictions'] = 0\n",
    "valid['Predictions'] = preds\n",
    "plt.plot(valid[['Close', 'Predictions']])\n",
    "plt.plot(train['Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataframe\n",
    "data = df.sort_index(ascending=True, axis=0)\n",
    "new_data = pd.DataFrame(index=range(0,len(df)),columns=['Date', 'Close'])\n",
    "for i in range(0,len(data)):\n",
    "    new_data['Date'][i] = data['Date'][i]\n",
    "    new_data['Close'][i] = data['Close'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting index\n",
    "new_data.index = new_data.Date\n",
    "new_data.drop('Date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating train and test sets\n",
    "dataset = new_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset[0:987,:]\n",
    "valid = dataset[987:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting dataset into x_train and y_train\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = [], []\n",
    "for i in range(60,len(train)):\n",
    "    x_train.append(scaled_data[i-60:i,0])\n",
    "    y_train.append(scaled_data[i,0])\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1],1)))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(x_train, y_train, epochs=1, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting 246 values, using past 60 from the train data\n",
    "inputs = new_data[len(new_data) - len(valid) - 60:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs  = scaler.transform(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "for i in range(60,inputs.shape[0]):\n",
    "    X_test.append(inputs[i-60:i,0])\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\n",
    "closing_price = model.predict(X_test)\n",
    "closing_price = scaler.inverse_transform(closing_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms=np.sqrt(np.mean(np.power((valid-closing_price),2)))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for plotting\n",
    "train = new_data[:987]\n",
    "valid = new_data[987:]\n",
    "valid['Predictions'] = closing_price\n",
    "plt.plot(train['Close'])\n",
    "plt.plot(valid[['Close','Predictions']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
